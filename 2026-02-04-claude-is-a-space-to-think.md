# Claude 是一个思考的空间
# Claude Is a Space to Think

> 原文链接: https://www.anthropic.com/news/claude-is-a-space-to-think
> 日期: 2026-02-04

---

## English

There are many good places for advertising. A conversation with Claude is not one of them.

Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We've run our own ad campaigns, and our AI models have, in turn, helped many of our customers in the advertising industry.

But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.

We want Claude to act unambiguously in our users' interests. So we've made a choice: Claude will remain ad-free. Our users won't see "sponsored" links adjacent to their conversations with Claude; nor will Claude's responses be influenced by advertisers or include third-party product placements our users did not ask for.

### The Nature of AI Conversations

When people use search engines or social media, they've come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.

Conversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it's also what makes them susceptible to influence in ways that other digital products are not.

Our analysis of conversations with Claude shows that an appreciable portion involve topics that are sensitive or deeply personal—the kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous—and, in many cases, inappropriate.

We still have much to learn about the impact of AI models on the people who use them. Early research suggests both benefits—like people finding support they couldn't access elsewhere—and risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity.

### Incentive Structures

Being genuinely helpful is one of the core principles of Claude's Constitution, the document that describes our vision for Claude's character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.

Consider a concrete example. A user mentions they're having trouble sleeping. An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align—but not always.

Even ads that don't directly influence an AI model's responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement—for the amount of time people spend using Claude and how often they return. These metrics aren't necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user's request without prompting further conversation.

We recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches might avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development. We've chosen not to introduce these dynamics into Claude.

### Our Approach

Anthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.

Expanding access to Claude is central to our public benefit mission, and we want to do it without selling our users' attention or data to advertisers. To that end, we've brought AI tools and training to educators in over 60 countries, begun national AI education pilots with multiple governments, and made Claude available to nonprofits at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it.

### Supporting Commerce

AI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We're particularly interested in the potential of agentic commerce, where Claude acts on a user's behalf to handle a purchase or booking end to end. And we'll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more—when they choose to do so.

All third-party interactions will be grounded in the same overarching design principle: they should be initiated by the user (where the AI is working for them) rather than an advertiser (where the AI is working, at least in part, for someone else).

### A Trusted Tool for Thought

We want our users to trust Claude to help them keep thinking—about their work, their challenges, and their ideas.

Our experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.

We think Claude should work the same way.

---

## 中文翻译

有很多好的广告位置。与 Claude 的对话不是其中之一。

广告推动竞争，帮助人们发现新产品，并使电子邮件和社交媒体等服务能够免费提供。我们自己也做过广告活动，而我们的 AI 模型也反过来帮助了广告行业的许多客户。

但在与 Claude 的对话中加入广告与我们希望 Claude 成为的东西不相容：一个真正有帮助的工作和深度思考助手。

我们希望 Claude 明确地以用户利益为行动准则。所以我们做出了选择：Claude 将保持无广告。用户不会在与 Claude 的对话旁边看到"赞助"链接；Claude 的回复也不会受广告商影响或包含用户未要求的第三方产品植入。

### AI 对话的本质

当人们使用搜索引擎或社交媒体时，他们已经习惯了有机内容和赞助内容的混合。从噪音中过滤信号是互动的一部分。

与 AI 助手的对话有着本质的不同。格式是开放式的；用户经常分享上下文并透露比搜索查询更多的信息。这种开放性是使 AI 对话有价值的部分原因，但它也使其以其他数字产品所没有的方式容易受到影响。

我们对与 Claude 的对话分析表明，相当一部分涉及敏感或深度个人的话题——那种你可能与信任的顾问进行的对话。许多其他用途涉及复杂的软件工程任务、深度工作或思考困难问题。在这些场景中出现广告会显得不协调——在许多情况下，是不恰当的。

### 激励结构

真正有帮助是 Claude 宪法的核心原则之一——该文档描述了我们对 Claude 性格的愿景并指导我们如何训练模型。基于广告的商业模式会引入可能与这一原则相违背的激励机制。

举一个具体的例子。一个用户提到他们睡眠困难。没有广告激励的助手会根据对用户最有洞察力的内容来探索各种潜在原因——压力、环境、习惯等等。一个有广告支持的助手则有额外的考量：对话是否提供了交易机会。这些目标可能经常一致——但并非总是如此。

即使不直接影响 AI 模型回复而是单独出现在聊天窗口中的广告，也会损害我们希望 Claude 成为的东西：一个清晰的思考和工作空间。此类广告还会引入优化参与度的激励——人们使用 Claude 的时间和回访频率。这些指标不一定与真正有帮助相一致。最有用的 AI 互动可能是一次短暂的互动，或者是解决用户请求而无需引发进一步对话的互动。

### 我们的方法

Anthropic 专注于企业、开发者和帮助用户蓬勃发展。我们的商业模式很直接：通过企业合同和付费订阅产生收入，并将收入重新投资于为用户改进 Claude。

扩大 Claude 的使用渠道是我们公益使命的核心，我们希望在不向广告商出售用户注意力或数据的情况下实现这一目标。为此，我们已向 60 多个国家的教育工作者提供了 AI 工具和培训，与多个政府启动了国家级 AI 教育试点，并以大幅折扣向非营利组织提供 Claude。

### 支持商业

AI 将越来越多地与商业互动，我们期待以帮助用户的方式支持这一点。我们对智能体商务的潜力特别感兴趣，即 Claude 代表用户端到端地处理购买或预订。

所有第三方互动都将基于同一总体设计原则：它们应由用户发起（AI 为他们工作），而不是由广告商发起（AI 至少部分地为其他人工作）。

### 值得信赖的思考工具

我们希望用户信任 Claude 帮助他们持续思考——关于他们的工作、挑战和想法。

我们使用互联网的经验使我们很容易假设我们使用的产品上的广告是不可避免的。但打开一个笔记本，拿起一个精心制作的工具，或者站在一块干净的黑板前，没有任何广告。

我们认为 Claude 应该以同样的方式工作。
