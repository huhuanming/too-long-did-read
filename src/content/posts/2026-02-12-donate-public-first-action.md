---
titleEn: "Anthropic Is Donating $20 Million to Public First Action"
titleZh: "Anthropic 向 Public First Action 捐赠 2000 万美元"
date: 2026-02-12
slug: donate-public-first-action
originalUrl: https://www.anthropic.com/news/donate-public-first-action
---

## English

AI will bring enormous benefits—for science, technology, medicine, economic growth, and much more. But a technology this powerful also comes with considerable risks.

Those risks might come from the misuse of the models: AI is already being exploited to automate cyberattacks; in the future it might assist in the production of dangerous weapons. Risks might also come from the models themselves: powerful AI systems can take harmful actions contrary to the intentions—and out of the control—of their users.

AI models are improving in their capabilities at a dizzying, increasing pace, from simple chatbots in 2023 to today's "agents" that complete complex tasks. At Anthropic, we've had to redesign a notoriously difficult technical test for hiring software engineers multiple times as successive AI models defeated each version. This rate of progress will not be confined to software engineering; indeed, many other professions are already seeing an impact.

Consequently, the AI policy decisions we make in the next few years will touch nearly every part of public life, from the labor market to online child protection to national security and the balance of power between nations.

In circumstances like these, we need good policy: flexible regulation that allows us to reap the benefits of AI, keep the risks in check, and keep America ahead in the AI race. That means keeping critical AI technology out of the hands of America's adversaries, maintaining meaningful safeguards, promoting job growth, protecting children, and demanding real transparency from the companies building the most powerful AI models.

We don't want to sit on the sidelines while these policies are developed. For that reason, Anthropic is contributing $20 million to Public First Action, a new bipartisan 501(c)(4) that will support public education about AI, promote safeguards, and ensure America leads the AI race.

Recent polling finds that 69% of Americans think the government is "not doing enough to regulate the use of AI." We agree. AI is being adopted faster than any technology in history, and the window to get policy right is closing. Yet there are no official guardrails in place and there is no federal framework on the horizon.

At present, there are few organized efforts to help mobilize people and politicians who understand what's at stake in AI development. Instead, vast resources have flowed to political organizations that oppose these efforts.

Public First Action is working to fill that gap. Founded and led both by Republican and Democratic strategists, it works across party lines to support policies on AI governance.

The organization will work with Republicans, Democrats, and Independents who share the same policy priorities:

- Insisting on AI model transparency safeguards that give the public more visibility into frontier AI companies' risk management;
- Supporting a robust federal AI governance framework — and opposing preemption of state laws unless Congress enacts stronger safeguards;
- Supporting smart export controls on AI chips that will keep America ahead of its authoritarian adversaries;
- Pursuing targeted regulation focused on the nearest-term high risks: AI-enabled biological weapons and cyberattacks

These policies aren't partisan. Nor are they for the benefit of Anthropic as an AI developer—effective AI governance means more scrutiny of companies like ours, not less. They're also not an attempt to hold back smaller or less well-resourced developers: our view is that transparency regulation, for example, should apply only to companies developing the most powerful (and most dangerous) AI models.

The companies building AI have a responsibility to help ensure the technology serves the public good, not just their own interests. Our contribution to Public First Action is part of our commitment to governance that enables AI's transformative potential and helps proportionately manage its risks.

---

## 中文翻译

AI 将带来巨大的好处——在科学、技术、医学、经济增长等诸多领域。但如此强大的技术也伴随着相当大的风险。

这些风险可能来自对模型的滥用：AI 已经被用于自动化网络攻击；未来它可能协助生产危险武器。风险也可能来自模型本身：强大的 AI 系统可能采取违背用户意图且超出用户控制的有害行动。

AI 模型的能力正以令人眩晕的、不断加速的步伐提升，从 2023 年的简单聊天机器人到今天完成复杂任务的"智能体"。在 Anthropic，我们不得不多次重新设计一个用于招聘软件工程师的出了名困难的技术测试，因为连续的 AI 模型击败了每个版本。这种进步速度不会局限于软件工程；事实上，许多其他行业已经看到了影响。

因此，我们在未来几年做出的 AI 政策决定将触及公共生活的几乎每个部分，从劳动力市场到在线儿童保护，再到国家安全和国家间的力量平衡。

在这种情况下，我们需要好的政策：灵活的监管，使我们能够获得 AI 的好处，控制风险，并使美国在 AI 竞赛中保持领先。这意味着将关键 AI 技术远离美国的对手，保持有意义的保障措施，促进就业增长，保护儿童，并要求构建最强大 AI 模型的公司真正透明。

我们不想在制定这些政策时袖手旁观。因此，Anthropic 向 Public First Action 捐赠 2000 万美元，这是一个新的两党 501(c)(4) 组织，将支持关于 AI 的公众教育，促进保障措施，并确保美国在 AI 竞赛中领先。

最近的民调发现，69% 的美国人认为政府"在监管 AI 使用方面做得不够"。我们同意。AI 被采用的速度比历史上任何技术都快，而制定正确政策的窗口正在关闭。然而，目前没有官方的防护措施，也没有联邦框架在望。

Public First Action 正在努力填补这一空白。它由共和党和民主党战略家共同创立和领导，跨越党派界限支持 AI 治理政策。

该组织将与分享相同政策优先事项的共和党人、民主党人和独立人士合作：

- 坚持 AI 模型透明度保障措施，让公众更多地了解前沿 AI 公司的风险管理；
- 支持强有力的联邦 AI 治理框架——反对在国会制定更强保障措施之前抢先取消州法律；
- 支持明智的 AI 芯片出口管制，使美国领先于其威权对手；
- 追求针对最近期高风险的定向监管：AI 驱动的生物武器和网络攻击

这些政策不是党派性的。它们也不是为了 Anthropic 作为 AI 开发者的利益——有效的 AI 治理意味着对像我们这样的公司进行更多审查，而不是更少。构建 AI 的公司有责任帮助确保该技术服务于公共利益，而不仅仅是它们自己的利益。
