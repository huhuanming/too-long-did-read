# Sharing Our Compliance Framework for California's Transparency in Frontier AI Act
# 分享我们对加利福尼亚前沿 AI 透明度法案的合规框架

> Source: https://www.anthropic.com/news/compliance-framework-SB53
> Date: 2025-12-19

---

California's Transparency in Frontier AI Act (SB 53) takes effect January 1, establishing the nation's first frontier AI safety and transparency requirements for catastrophic risks.

加利福尼亚州的《前沿 AI 透明度法案》（SB 53）于 1 月 1 日生效，确立了全国首个针对灾难性风险的前沿 AI 安全和透明度要求。

Anthropic endorsed SB 53 because frontier AI developers should be transparent about assessing and managing risks. The law balances strong safety practices, incident reporting, and whistleblower protections while preserving flexibility in implementation and exempting smaller companies from regulatory burdens.

Anthropic 支持 SB 53，因为前沿 AI 开发者应该对评估和管理风险保持透明。该法律在强有力的安全实践、事件报告和举报人保护之间取得平衡，同时保留了实施的灵活性，并免除了较小公司的监管负担。

---

## What's in Our Frontier Compliance Framework
## 我们的前沿合规框架包含什么

Anthropic's Frontier Compliance Framework (FCF) describes assessment and mitigation of cyber offense, chemical, biological, radiological, nuclear threats, and AI sabotage risks. It outlines a tiered system for evaluating model capabilities and explains mitigation approaches, including model weight protection and safety incident response.

Anthropic 的前沿合规框架（FCF）描述了对网络攻击、化学、生物、放射性、核威胁和 AI 破坏风险的评估和缓解。它概述了评估模型能力的分级系统，并解释了缓解方法，包括模型权重保护和安全事件响应。

The FCF reflects practices Anthropic has followed for years. Since 2023, the Responsible Scaling Policy (RSP) has guided the company's approach to managing extreme risks from advanced AI systems. The company releases detailed system cards when launching models describing capabilities, safety evaluations, and risk assessments. Moving forward, the FCF serves as the compliance framework for SB 53, while the RSP remains the voluntary safety policy.

FCF 反映了 Anthropic 多年来一直遵循的实践。自 2023 年以来，负责任扩展政策（RSP）一直指导着该公司管理先进 AI 系统极端风险的方法。该公司在推出模型时发布详细的系统卡，描述能力、安全评估和风险评估。展望未来，FCF 将作为 SB 53 的合规框架，而 RSP 仍然是自愿性的安全政策。

---

## The Need for a Federal Standard
## 联邦标准的必要性

SB 53 formalizes transparency practices responsible labs already follow voluntarily, preventing abandonment as models become more capable or competition intensifies. A federal AI transparency framework is now needed for consistency nationwide.

SB 53 将负责任的实验室已经自愿遵循的透明度实践正式化，防止随着模型能力增强或竞争加剧而放弃这些实践。现在需要一个联邦 AI 透明度框架来实现全国一致性。

Anthropic's proposed federal framework emphasizes public visibility into safety practices without locking in specific technical approaches. Core tenets include:

Anthropic 提议的联邦框架强调让公众了解安全实践，同时不锁定特定的技术方法。核心原则包括：

- Requiring developers to publish frameworks describing risk assessment and mitigation
- 要求开发者发布描述风险评估和缓解的框架

- Publishing system cards documenting testing and evaluation upon deployment
- 在部署时发布记录测试和评估的系统卡

- Protecting whistleblowers from retaliation for raising compliance concerns
- 保护举报人免受因提出合规问题而遭受的报复

- Establishing flexible, lightweight standards that can adapt as best practices evolve
- 建立灵活、轻量级的标准，可随最佳实践的发展而调整

- Limiting requirements to established frontier developers building the most capable models
- 将要求限制在构建最强大模型的成熟前沿开发者

As AI systems grow more powerful, the public deserves visibility into development practices and safeguards. Anthropic looks forward to working with Congress to develop a national transparency framework ensuring safety while preserving America's AI leadership.

随着 AI 系统变得更加强大，公众有权了解开发实践和安全措施。Anthropic 期待与国会合作，制定一个既确保安全又保持美国 AI 领导地位的国家透明度框架。
