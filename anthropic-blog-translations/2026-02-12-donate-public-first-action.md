# Anthropic Is Donating $20 Million to Public First Action
# Anthropic 向 Public First Action 捐赠 2000 万美元

> Source: https://www.anthropic.com/news/donate-public-first-action
> Date: 2026-02-12

---

Anthropic announced a $20 million contribution to Public First Action, a bipartisan 501(c)(4) organization focused on AI governance and public education.

Anthropic 宣布向 Public First Action 捐赠 2000 万美元，这是一个专注于 AI 治理和公众教育的两党 501(c)(4) 组织。

---

The company states that AI offers substantial advantages for science, medicine, and economic growth, yet poses considerable risks. These risks stem from both potential misuse—such as automating cyberattacks—and from the systems themselves, which can "take harmful actions" beyond user control.

该公司表示，AI 为科学、医学和经济增长提供了巨大优势，但也带来了相当大的风险。这些风险既源于潜在的滥用——如自动化网络攻击——也源于系统本身，这些系统可能会采取超出用户控制的"有害行为"。

---

The article emphasizes that AI capabilities are advancing rapidly. Anthropic notes it has had to redesign its engineering hiring evaluations multiple times as successive AI models defeated previous versions, and this trend extends across professions.

文章强调 AI 能力正在快速进步。Anthropic 指出，由于后续的 AI 模型不断超越前一版本，公司不得不多次重新设计工程招聘评估，而这一趋势正在扩展到各个职业领域。

---

## Policy Priorities
## 政策优先事项

Public First Action will pursue four key objectives:

Public First Action 将追求四个关键目标：

- AI model transparency safeguards giving public visibility into how frontier companies manage risks
- AI 模型透明度保障措施，让公众了解前沿公司如何管理风险

- A robust federal AI governance framework, opposing state law preemption without stronger congressional safeguards
- 强有力的联邦 AI 治理框架，反对在没有更强国会保障的情况下由联邦法律取代州法律

- Smart export controls on AI chips to maintain American technological advantage
- 对 AI 芯片实施智慧出口管制，以维持美国的技术优势

- Targeted regulation addressing immediate high-risk applications like AI-enabled biological weapons and cyberattacks
- 有针对性的监管，应对 AI 赋能的生物武器和网络攻击等即时高风险应用

---

Anthropic emphasizes these policies are non-partisan and will actually increase scrutiny of companies like itself. The organization also clarifies that transparency rules should apply only to developers of the most powerful AI models, not smaller competitors.

Anthropic 强调这些政策是无党派的，实际上会增加对自身等公司的审查。该组织还澄清，透明度规则应仅适用于最强大 AI 模型的开发者，而非较小的竞争对手。

The company frames this as fulfilling its responsibility to ensure AI serves "the public good, not just their own interests."

该公司将此定位为履行其确保 AI 服务于"公共利益，而非仅服务于自身利益"的责任。
